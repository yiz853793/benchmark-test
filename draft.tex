\documentclass[sigplan, screen, 10pt]{acmart}

\renewcommand\footnotetextcopyrightpermission[1]{}
\settopmatter{printfolios=false,printccs=false,printacmref=false}

% \acmYear{2024}
% \copyrightyear{2024}
\acmConference[Brown CS1380'24]{Brown's Distributed Computing Systems}{Spring, 2024}{Providence, RI}
% \acmBooktitle{}
% \acmPrice{}
% \acmDOI{}
% \acmISBN{}

\usepackage{enumitem}
\usepackage{booktabs}
\usepackage{soul}
\usepackage{xspace}
\usepackage{color}
\usepackage{xcolor}
\usepackage{upquote}
\usepackage{listings}
\usepackage{amsmath}
\usepackage{wrapfig}
\usepackage{syntax}
\usepackage{caption}
\usepackage{picins}
\usepackage{minted}

\newcommand{\eg}{{\em e.g.}, }
\newcommand{\ie}{{\em i.e.}, }
\newcommand{\etc}{{\em etc.}\xspace}
\newcommand{\vs}{{\em vs.} }
\newcommand{\cf}[1]{(\emph{Cf}.\S\ref{#1})}
\newcommand{\sx}[1]{(\S\ref{#1})}
\newcommand{\sys}{{\scshape pSys}\xspace}


% \bibliographystyle{ACM-Reference-Format}
\bibliographystyle{unsrt}

\usepackage{booktabs}
\usepackage{subcaption}

\title{Performance Shell Benchmark \newline
\emph{Correctness, Efficiency, and Beyond}}

\author{Yizhang Xu}
\affiliation{BUPT}
\email{xuyizhang@bupt.edu.cn}

\begin{document}

\begin{abstract}
Shell script\cite{johnson2006shell} is pivotal in tackling diverse real-world issues such as COVID-19 analytics\cite{agbehadji2020review}, NLP(Natural Language Processing)\cite{ofer2021language}, and data analysis. 
Yet, they can be prone to failure or inefficiency.
This paper rigorously assesses the reliability and speed of these benchmark shell scripts.
For verifying output integrity, this study leverage SHA-256 hashes\cite{manankova2022cryptanalysis} and the diff utility\cite{blum2008linux} for swift and accurate comparisons with the correct outputs.
To measure performance, the time command is employed to capture and log execution times.
Ultimately, our analysis reveals that 82/204 of the shell script outputs are accurate, demonstrating robust performance even under the demands of large-scale data processing.

\textbf{Keyword} Shell Script, PaSh, Reliability and Speed, Performance Measurement, SHA-256 hashes
\end{abstract}

\maketitle

\section{Introduction}
\label{intro}
Shell is a command-line interface for interacting with the operating system\cite{newham2005learning}.
In the dynamic landscape of computer science, shell scripts are indispensable tools that frequently engage with complex text problems, playing a pivotal role in the functionality of computer systems\cite{naik2018learning}.
It is not uncommon for a system to house hundreds of these scripts, each a thread in the tapestry of system operations\cite{leite2014deploying}\cite{goforth2013role}.
By leveraging parallelization systems like POSH\cite{raghavan2020posh}, PaSh\cite{vasilakis2021pash}, and DiSh\cite{mustafa2023dish}, among others, computers can significantly enhance script execution speed.\par
The core of the issue lies in the imperative to ensure the scripts' accuracy and performance. 
A deviation from the intended path or a substandard execution mode can lead to inefficiencies and, more critically, to erroneous outcomes that undermine the integrity of the system's operations\cite{goforth2013role}.\par
To address these concerns, this paper embarks on a meticulous examination of shell scripts across four repositories. 
Our approach involves a blend of testing, debugging, and the provision of strategic advice aimed at optimizing the scripts' performance.\par
Our findings are both revealing and instructive: out of 204 shell scripts tests, 82 successfully delivered correct results. 
However, one script's performance stood out, taking over 5 minutes to handle a 1GB text file, underscoring the necessity for performance enhancements, especially when dealing with voluminous data sets.

\section{Related Work}
\label{related}
This study focuses on evaluating and optimizing the performance of benchmark scripts\cite{binpashbenchmark}, particularly their efficiency and accuracy when processing large-scale datasets.\par
PaSh\cite{vasilakis2021pash} is a system for parallelizing shell scripts, and it generates benchmark scripts used for testing in this study.
PaSh highlights the widespread use of POSIX shell scripts in system management, automation, and data processing, but also points out the inefficiency of their typically sequential execution.\par
DiffStream\cite{kallas2020diffstream} is a system designed to facilitate differential testing for stream processing programs.
DiffStream compares the outputs of different versions of a program or different programs running on the same data streams, highlighting any inconsistencies between them.
This study follows DiffStream's method and evaluate PaSh benchmark.\par
This study bears similarities to the work conducted by the KISTI team \cite{kim2015webshark}.   
They also established a standard dataset for assessing and comparing tool performance.
However, our study emphasizes simplifying the installation, execution, and data collection of benchmark suites through an automated process, especially on the simulated the benchmark shell scripts.\par
The project "NVIDIA Performance Testing for Emulation of the Grace CPU"\cite{fan2021nvidia}, is directly related to this study.
They developed a novel tool that consolidates other test suites for more convenient testing of NVIDIA's simulated CPU. 
Building upon their work, this study further explores how to enhance benchmark efficiency and maintainability through script optimization and the use of high-level programming languages.\newline

\section{Example of Benchmark Test}
\label{ex}

\textbf{An Example:}
Take \textbf{oneliners} as an example of our evaluation. To evaluate the execution time of scripts categorized under \textbf{oneliners}, you can follow these steps:
\subsection{Inputs:}
\begin{minted}[fontsize=\footnotesize]{shell}
./inputs.sh
\end{minted}
In the inputs.sh script, data is downloaded into the designated directory named inputs.
\subsection{Run}
\begin{minted}[fontsize=\footnotesize]{shell}
./run.sh --small
\end{minted}
The run.sh script is responsible for executing all shell programs located in the scripts folder. It also logs the time taken for each execution and appends this information to a file named \textbf{oneliners}.res within the output folder. The "--small" option, when specified, indicates that the shell should be run with a smaller dataset to expedite the execution process. Ideally, repeat this step five times and take the average as the final time.
\subsection{Verify}
\begin{minted}[fontsize=\footnotesize]{shell}
./verify.sh --small
\end{minted}
The verify.sh script performs a check on the correctness of the output generated by the shell programs in the scripts folder. When the "--small" option is applied, it ensures that the shell program outputs are accurate even when run with the reduced dataset.
\subsection{Clear}
\begin{minted}[fontsize=\footnotesize]{shell}
./cleanup.sh
\end{minted}
The cleanup.sh script is designed to perform a cleanup operation by removing downloaded files and generated outputs, thereby freeing up system memory.

\subsection{Results}
The results of these operations, including timing and verification outcomes, are compiled and recorded in the oneliners.res file.\newline
\texttt{executing oneliners bash 08.05.2024 Monday 15:40:23 CST}
\texttt{./scripts/nfa-regex.sh 2.460} \newline
\texttt{./scripts/sort.sh 0.076}\newline
\texttt{./scripts/top-n.sh 0.309}\newline
\texttt{./scripts/wf.sh 0.285}\newline
\texttt{./scripts/spell.sh 0.529}\newline
\texttt{./scripts/diff.sh 0.138}\newline
\texttt{./scripts/bi-grams.sh 0.392}\newline
\texttt{./scripts/set-diff.sh 0.187}\newline
\texttt{./scripts/sort-sort.sh 0.126}\newline
\texttt{./scripts/shortest-scripts.sh 0.698}

\section{Background}
\label{bg}
This paper depends on the following techniques and shell scripts code.
\subsection{PaSh}
PaSh\cite{vasilakis2021pash} is an innovative system designed for the parallelization of POSIX shell scripts.
At its core, PaSh automatically transforms scripts into a dataflow graph, revealing potential parallel execution paths through a series of semantic-preserving transformations.
It then recompiles the optimized dataflow graph back into a script, incorporating specific POSIX directives and PaSh's proprietary runtime primitives to ensure the efficiency and correctness of parallel execution.
PaSh offers a concise annotation language that allows command developers to easily mark the parallel characteristics of their commands. 
Tested across multiple Unix scripts, PaSh has demonstrated significant performance improvements, affirming its effectiveness in automating the parallelization of scripts.
\subsection{Shell Script Benchmarks}
Shell script benchmark\cite{binpashbenchmark} repository under binpash on GitHub is a curated collection of 16 benchmark programs and 105 shell scripts enhanced with PaSh. 
This resource provides a robust platform for assessing the impact of parallelization on shell script execution. 
It offers a diverse range of scripts, from simple to complex, enabling a comprehensive evaluation of PaSh's ability to accelerate shell-based workflows.
The repository is a valuable tool for developers and researchers working in parallel computing within the shell scripting domain.\newline

\section{Implementation}
\label{tec}
To achieve the desired outcome, adhere to the following sequential steps:
\subsection{Linux Environment and PaSh}
\textbf{Virtual Machine Installation:} On your Windows or macOS system, begin by installing a virtual machine software such as VMware. Proceed to set up an Ubuntu image file within this virtual environment.\newline
\textbf{Installing PaSh:} Install the PaSh by executing the following command in terminal\cite{vasilakis2021pash}:
\begin{minted}[fontsize=\footnotesize]{shell}
wget https://raw.githubusercontent.com/binpash/pash/main/scripts
/up.sh
sh up.sh
export PASH_TOP="$PWD/pash/"
## Run PaSh with echo hi
"$PASH_TOP/pa.sh" -c "echo hi"
\end{minted}
\subsection{Benchmark}
Install the binpash/benchmark repository by executing the following command in terminal:
\begin{minted}[fontsize=\footnotesize]{shell}
git clone https://github.com/binpash/benchmarks.git
\end{minted}
For the vast majority of projects, run by imitating the Example section.
If there are special requirements, refer to the README file.


\section{Evaluation}
\label{eval}
To conduct a comprehensive benchmark evaluation, we have selected four packages from the benchmark suite and aim to address the following inquiries:
\begin{itemize}
\item[\textbf{Q1:}] Do the shell scripts produce the correct outcomes?(5.1)
\item[\textbf{Q2:}] How does the shell script perform when processing extensive datasets?(5.2)
\end{itemize}
The run.sh executes all scripts and record the running time.
The verify.sh compare the hash values of the shell script outputs with the hash values of the expected answers.
If the scripts complete their tasks in under 600 seconds when dealing with large-scale data, they are deemed efficient.
The congruence of these hashes will confirm the correctness of the shell script's response.
\subsection{Correctness}
Overall, 40.2\% (82/204) of the outputs matched the benchmark hashes. The detailed breakdown by category is as follows:
\begin{itemize}
    \item covid-mts: 0\% (0/4) of outputs matched.
    \item nlp: 41.1\% (78/190) of outputs matched.
    \item oneliners: 40\% (4/10) of outputs matched.
\end{itemize}
The scripts nfa-regex.sh, spell.sh, top-n.sh, and wf.sh produced correct outputs.
However, the verify.sh script within the file-enc suite was empty, and the file-enc directory did not include the necessary folder hashes.
Due to these omissions, the paper is unable to verify the correctness of the shell scripts in the file-enc.\newline


\subsection{Efficiency}
\textbf{Covid-mts:}
The execution time of the scripts in the covid-mts are detailed in Table 1.
All the scripts completed their task in 300s when dealing with a 3.4GB file.
The 3.sh cost the most of time, taking 80.081s on average.
The 1.sh and 2.sh cost neerly the same, separately using 66.137s and 66.069s.
The 4.sh cost least, using 25.581s.
 
\begin{table}[]
    \centering
    \begin{tabular}{c|c|c|c}
         \textbf{covid-mts}& \textbf{AVG/s} & \textbf{MAX time/s} & \textbf{Min time/s} \\
         \hline
         1.sh & 66.137 & 66.589 & 65.766 \\
         2.sh & 66.069 & 66.383 & 65.747\\
         3.sh & 80.081 & 80.725 & 79.639 \\
         4.sh & 25.581 & 25.728 & 25.462 \\
         \hline
    \end{tabular}
    \caption{running time of covid-mts scripts}
    % \label{tab:my_label}
\end{table}

\textbf{Oneliners:}
The execution times of the scripts in oneliners are detailed in Table 2.
All scripts completed their tasks in under 300s when processing 334MB of data.
Among them, the nfa-regex.sh script demonstrated the highest latency, with an average runtime of 126.397s.
The average execution time of bi-grams.sh is 66.214.
The execution time of wf.sh, top-n.sh, spell.sh is around 45s, separately 45.137s, 45.090s, 43.705s.
The average execution time of set-diff.sh is 34.588s.
The execution time of sort-sort.sh, shortest-scripts.sh and diff.sh is nearly the same, separately 19.489s, 18.005s and 16.189.
The sort.sh cost the least, whose average execution time is 13.330s.
The relatively high runtime of nfa-regex.sh can be attributed to its need to match complex regular expressions over the input data, which is inherently a more resource-intensive task.

\begin{table}[]
    \centering
    \begin{tabular}{c|c|c|c}
        \textbf{oneliners}& \textbf{AVG/s} & \textbf{MAX time/s} & \textbf{Min time/s} \\
         \hline
         nfa-regex.sh & 126.397 & 127.222 & 126.010 \\
         bi-grams.sh & 66.214 & 67.416 & 65.693\\
         wf.sh & 45.137 & 45.225 & 45.006 \\
         top-n.sh & 45.090 & 45.158 & 45.038 \\
         spell.sh & 43.705 & 44.169 & 43.531 \\
         set-diff.sh & 34.588 & 34.840 & 34.472\\
         sort-sort.sh & 19.489 & 19.576 & 19.436 \\
         shortest-scripts.sh & 18.005 & 18.045 & 17.947\\
         diff.sh & 16.189 & 16.312 & 16.050 \\
         sort.sh & 13.330 & 13.354 & 13.275 \\
         \hline
    \end{tabular}
    \caption{running time of oneliners scripts}
    % \label{tab:my_label}
\end{table}

\textbf{Nlp:}
The execution times of the scripts in oneliners are detailed in Table 3.
All scripts completed their tasks in under 300s when processing totally 71MB of data.
The 8\_3.3.sh runs the longest time, on average 44.605s. Then execution times of  the 4\_3b.sh, 4\_3.sh, 8.2\_2.sh, 3\_3.sh, 6\_2.sh and 8.3\_2.share are around 30s, separately 32.622s, 31.419s, 30.545s, 30.370s,  28.735s, 27.188s.
Then the execution times of 3\_2.sh, 8\_1.sh, 1\_1.sh, 6\_1\_2.sh, 2\_1.sh, 8.2\_1.sh are around 20s, separately 24.198s, 23.375s, 21.442s, 20.803s,19.857s, 19.676s.
Then the execution times of 7\_2.sh and 6\_4.sh are nearly the same, separately 16.928s and 13.906s. Next, the execution times of 6\_5.sh, 6\_3.sh and 6\_1\_1.sh are around 9s, separately 9.415s,  9.008s and 8.359s. 
Then the execution times of 7\_1.sh, 6\_1.sh, 2\_2.sh, 3\_1.sh, and 6\_7.sh are under 5s, separately 4.780s, 4.458s,  3.407s, 2.921s, 1.924s.

\begin{table}[]
    \centering
    \begin{tabular}{c|c|c|c}
         \textbf{nlp}& \textbf{AVG/s} & \textbf{MAX time/s} & \textbf{Min time/s} \\
         \hline
         1_1.sh & 21.442 & 21.787 & 21.148 \\
         2_1.sh & 19.857 & 20.050 & 19.664 \\
         2_2.sh & 3.407 & 3.465 & 3.345 \\
         3_1.sh & 2.921 & 23.533 & 22.577\\
         3_2.sh & 24.198 & 24.366 & 24.073\\
         3_3.sh & 30.370 & 30.588 & 20.080\\
         4_3.sh & 30.545 & 31.124 & 29.963\\
         4_3b.sh & 32.622&  33.702& 31.876\\
         6_1.sh & 4.458 & 4.693 & 4.371 \\
         6_1_1.sh & 8.359& 8.668 & 8.128\\
         6_1_2.sh & 20.803 & 21.029 & 20.608\\
         6_2.sh & 28.735 & 29.131 & 28.418 \\
         6_3.sh & 9.008 & 9.128 & 8.807 \\
         6_4.sh & 13.906 & 14.187 & 13.677 \\
         6_5.sh & 9.415 &  9.697& 9.211\\
         6_7.sh & 1.924 & 1.980 & 1.879\\
         7_1.sh & 4.780 & 4.814 & 4.672 \\
         7_2.sh & 16.928 & 17.180 & 16.788\\
         8_1.sh & 23.375 & 23.685 & 22.993\\
         8.2_1.sh & 19.676 & 19.810 & 19.500\\
         8.2_2.sh & 31.419 & 31.749 & 30.961 \\
         8.3_2.sh & 27.188 & 27.937 & 26.897\\
         8_3.3.sh & 44.605 & 45.207 & 44.024\\
         \hline
    \end{tabular}
    \caption{running time of nlp scripts}
    % \label{tab:my_label}
\end{table}

\textbf{File-enc:}
The execution times of the scripts in file-enc are detailed in Table 4.
The compress\_files.sh runs 443.042s on average, whose execution exceeds 300 seconds.
The encrypt\_files.sh runs 84.374s on average.\par
The compress\_files.sh compress the .png file using gzip command.
The execution time of gzip depends on the compression level.
The encrypt\_files.sh transfrom the file into another file via CBC encrypt mode.

\begin{table}[]
    \centering
    \begin{tabular}{c|c|c|c}
        \textbf{file-enc}& \textbf{AVG/s} & \textbf{MAX time/s} & \textbf{Min time/s} \\
         \hline
         compress_files.sh & 443.042 & 443.293 & 442.672 \\
         encrypt_files.sh & 84.374 & 84.676 & 84.068 \\
         \hline
    \end{tabular}
    \caption{running time of file-enc scripts}
    % \label{tab:my_label}
\end{table}

\section{Discussion}
\label{dis}

The file-enc has some bug.
The first one is that in run.sh input\_dir is wrong and it needs go to the folder inputs.
Change like this can solve this bug.
\begin{minted}[fontsize=\footnotesize]{shell}
# in run.sh wrong in line 9 and 12
input_dir="inputs/pcap_data_small" # should go to inputs
\end{minted}

The second is that in compress\_files.sh and in encrypt\_files.sh and miss a folder too.
\begin{minted}[fontsize=\footnotesize]{shell}
# in compress_files.sh, wrong in line 8
cat $1/$item | gzip -1 -c > $2/$output_name #miss $1
\end{minted}

\begin{minted}[fontsize=\footnotesize]{shell}
# in encrypt_files.sh, wrong in line 17
cat $1/$item | pure_func > $2/$output_name # miss $1 too
\end{minted}
After add the folder, scripts can run successfully.

\section{Conclusion}
\label{conclusion}
The paper test several repositories in benchmark and evaluate the correctness and efficiency. Most of the shell scripts may output in a wrong format which cause the low correct rate. 
Most execution time of shell scripts is less than 300s when processing in the large-scale data, showing efficiency of these shell. \par
All the data are open source and available for download: \href{https://github.com/yiz853793/benchmark-test}{https://github.com/yiz853793/benchmark-test.}


%% Bibliography
{\small
\bibliography{./bib}
}

\end{document}
